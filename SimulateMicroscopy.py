#!/usr/bin/env python

#> \file
#> \author David Ladd
#> \brief 
#>
#> \section LICENSE
#>
#> Version: MPL 1.1/GPL 2.0/LGPL 2.1
#>
#> The contents of this file are subject to the Mozilla Public License
#> Version 1.1 (the "License"); you may not use this file except in
#> compliance with the License. You may obtain a copy of the License at
#> http://www.mozilla.org/MPL/
#>
#> Software distributed under the License is distributed on an "AS IS"
#> basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
#> License for the specific language governing rights and limitations
#> under the License.
#>
#> \section DESCRIPTION
#>
#> This program interpolates irregularly spaced data onto a regular grid.
#> The intended use is to interpolate fluorescence data from irregularly
#> spaced nodal points in a finite element reaction-diffusion model onto
#> a regular grid, simulating an experimental fluorescence signal.
#<

import results.utilities as util
import numpy as np
import math
import pandas as pd
import naturalneighbor
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import skimage.io
from scipy import signal
import trimesh
import scipy
import scipy.io
from scipy import ndimage

#=================================================================
# C l a s s e s
#=================================================================

class fieldInfo(object):
    'base class for info about fields'
    def __init__(self):
        self.region = ''
        self.group = ''
        self.numberOfFields = 0
        self.fieldNames = []
        self.numberOfFieldComponents = []

# =====================================
# C o n t r o l   P a n e l
# =====================================
# -------------------------------------
# Input nodal irregular data info
# -------------------------------------
stopTime = 30.                             # finish time for the FEM simulation (ms)
startTime = 0.0                            # start time for the FEM simulation (ms)  
timeIncrement = 0.1                        # timestep increment (ms)
numberOfProcessors = 4                    # number of processors if run as an MPI job
species = [3]                          # Ca(1), F(2), FCa(3), CaM(4), CaMCa(5), ATP(6), ATPCa(7)
speciesLabel = ['FCa']
dependentFieldNumber = 2                   # The dependent field of interest
outputFrequency = 50                       # the output frequency of the FEM solver (or desired frequency to read the node data files at)
regSpace =  0.05375 #1075 #0.0215 0.05375  # in um
outputSpacingStep = 4
psfFile = 'psf53.tif'
roundTo = regSpace
initFCa = 2.08
padding = 0
SNR = 100.0
#numSlicesEachSide = 10

# -------------------------------------
# Identify FEM I/O files
# -------------------------------------
meshDir = '/ssd/opencmiss/projects/cardiac_ecc/meshinputs/'
nodeFile = meshDir + 'Combined_8Sarc_1319kNodes_node.h5'  #'Combined_8Sarc_1436kNodes_node.h5'  #1319
path = "/ssd/opencmiss/projects/cardiac_ecc/results/extrusion/timelag/8Sarc/1319kNodes/Mito/n4/"
inputPath = path + "output/"
surfaceMaskFile = meshDir + "Combined_8Sarc_503kNodes_surfaceFixed.stl"
boundaryTol = 2.1*regSpace
caclean_path = '/home/dladd/CaCLEAN/'

# -------------------------------------
# Identify RyR I/O files
# -------------------------------------
spacingType = "1umSpacing"
mitoModel = 'Mito'
numSarc = 8
numRyrPerSarc = 51 #123
maxClustersPerSlice = 200
numberOfKNodes = 1319 #1436 #1319
#ryrClusterCentersDir = ('/home/dladd/RyR-simulator/output-files/target-tomo-cell-parallel-offset05-N123/')
ryrClusterCentersDir = ('/home/dladd/RyR-simulator/output-files/target-tomo-cell-parallel-hardcore-nooffset_N50_h1/')
detectRyrTol = 0.2
detectRyrTolInc = 0.01
detectRyrTolMax = 1.5000001
# -------------------------------------


# Read in the node and element maps generated by tetgen
store = pd.HDFStore(nodeFile)
df = store['Node_Coordinates']
totalNumberOfNodes = df.shape[0]
nodeX = np.ascontiguousarray(df.iloc[:, 0].values)
nodeY = np.ascontiguousarray(df.iloc[:, 1].values)
nodeZ = np.ascontiguousarray(df.iloc[:, 2].values)
nodeGeom = np.asarray(df)
store.close()

# -------------------------------------
# Output regular data info
# -------------------------------------
xGridMax = (math.ceil(np.max(nodeX)/(roundTo*outputSpacingStep))  + padding)*(roundTo*outputSpacingStep)
xGridMin = (math.floor(np.min(nodeX)/(roundTo*outputSpacingStep)) - padding)*(roundTo*outputSpacingStep)
yGridMax = (math.ceil(np.max(nodeY)/(roundTo*outputSpacingStep))  + padding)*(roundTo*outputSpacingStep)
yGridMin = (math.floor(np.min(nodeY)/(roundTo*outputSpacingStep)) - padding)*(roundTo*outputSpacingStep)
zGridMax = (math.ceil(np.max(nodeZ)/(roundTo*outputSpacingStep))  + padding)*(roundTo*outputSpacingStep)
zGridMin = (math.floor(np.min(nodeZ)/(roundTo*outputSpacingStep)) - padding)*(roundTo*outputSpacingStep)

gridDimensions = [(int((xGridMax - xGridMin)/regSpace + roundTo/100.0)+1),
                  (int((yGridMax - yGridMin)/regSpace + roundTo/100.0)+1),
                  (int((zGridMax - zGridMin)/regSpace + roundTo/100.0)+1)]

xGrid = [xGridMin, xGridMax, gridDimensions[0]*1j]
yGrid = [yGridMin, yGridMax, gridDimensions[1]*1j]
zGrid = [zGridMin, zGridMax, gridDimensions[2]*1j]
grid_ranges = [xGrid, yGrid, zGrid]

x = np.linspace(xGrid[0], xGrid[1], gridDimensions[0])[0:gridDimensions[0]:outputSpacingStep]
y = np.linspace(yGrid[0], yGrid[1], gridDimensions[1])[0:gridDimensions[1]:outputSpacingStep]
z = np.linspace(zGrid[0], zGrid[1], gridDimensions[2])[0:gridDimensions[2]:outputSpacingStep]

print(x)
print(y)
print(z)
xLen = len(x)
yLen = len(y)
zLen = len(z)
totalNumberOfGridPoints = xLen*yLen*zLen
# Create a list of points from the regular grid
grid = np.zeros((totalNumberOfGridPoints, 3))
c = 0
for i in range(xLen):
    for j in range(yLen):
        for k in range(zLen):
            grid[c] = [x[i], y[j], z[k]]
            c += 1

# # -------------------------------------
# # Read in FEM nodal data
# # -------------------------------------
# Get number of timesteps
totalSimTime = stopTime - startTime
numberOfTimesteps = 1
if totalSimTime > timeIncrement:
    numberOfTimesteps += int((totalSimTime/timeIncrement)/outputFrequency)

print('Number of timsteps: ' + str(numberOfTimesteps))
# Collect geometry and species data from OpenCMISS .exnode files
fields = fieldInfo()
specData = np.zeros((numberOfTimesteps, totalNumberOfNodes))

nn_interp = np.zeros((numberOfTimesteps, gridDimensions[0], gridDimensions[1], gridDimensions[2]))

outString = str(int(totalNumberOfNodes/1000)) + 'kNodes'
specGeomDataFile = inputPath + '/FCa_' + outString + '_' +  str(numberOfTimesteps) + 'timesteps.npz'
try:
    with open(specGeomDataFile):
        print('Reading FEM data from: ' + specGeomDataFile)
        loaded = np.load(specGeomDataFile)
        specData = loaded['spec']
        nodeGeom = loaded['geom']
except:
    for timestep in range(numberOfTimesteps):
        nodeData = np.zeros((totalNumberOfNodes,4))
        outputStep = timestep * outputFrequency
        s = 0
        for speciesNumber in species:
            filenameRoot = inputPath + '/TIME_STEP_SPEC_'+ str(speciesNumber) + '.part'
            for proc in range(numberOfProcessors):
                filename = filenameRoot + str(proc).zfill(2) + '.' + str(outputStep).zfill(3) + '.exnode'
                #filename += str(proc).zfill(2) + '.300.exnode'
                importNodeData = np.zeros((totalNumberOfNodes,4))
                print('Reading: ' + filename)
                util.readExnode(filename,fields,importNodeData,totalNumberOfNodes,dependentFieldNumber)
                nodeData += importNodeData
            specData[timestep] = nodeData[:,3]
            s+=1
    print('Saving nodal data to: ' + specGeomDataFile)
    np.savez_compressed(specGeomDataFile, spec=specData, geom=nodeGeom)


for timestep in range(numberOfTimesteps):
    print('   Performing discrete Sibson interpolation, Time (ms): ' + str(timestep*timeIncrement*outputFrequency))
    specData[timestep, specData[timestep] < 0.01] = initFCa
    nn_interp[timestep] = naturalneighbor.griddata(nodeGeom, specData[timestep], grid_ranges)

# -------------------------------------
# Convolve image against selected PSF
# -------------------------------------
convolve = True
if convolve:
    convolved = np.zeros_like(nn_interp)
    psfOrig = skimage.io.imread(psfFile)
    # in our case, the y-axis is the z depth for the simulated microscopy
    psf = np.moveaxis(psfOrig, 2, 1)
    magPsf = sum(sum(sum(psf)))
    for timestep in range(numberOfTimesteps):
        print('Convolving interpolated image with PSF, timestep: ' + str(timestep))
        convolved[timestep] = signal.convolve(nn_interp[timestep], psf, mode='same') # / magPsf
        #convolved[timestep] = ndimage.convolve(nn_interp[timestep], psf, mode='constant') / magPsf

# -------------------------------------
# Select 2D slice and export
# CaCLEAN fields to a MatLab .mat file
# -------------------------------------
ryrCentersOrig = np.zeros((numRyrPerSarc*numSarc, 3))
zOffset = 1.0
for s in range(numSarc):
    sarcRyr = np.loadtxt(ryrClusterCentersDir+'simPP'+str(s+1)+'.txt')
    sarcRyr[:, 2] += zOffset
    ryrCentersOrig[s*numRyrPerSarc:(s+1)*numRyrPerSarc, :] = sarcRyr
    zOffset += 2.0

# x/y seems to be flipped in the ryrCenters file?
ryrCenters = np.zeros_like(ryrCentersOrig)
ryrCenters[:, 0] = ryrCentersOrig[:, 1]
ryrCenters[:, 1] = ryrCentersOrig[:, 0]
ryrCenters[:, 2] = ryrCentersOrig[:, 2]
print(ryrCenters)


# tolerances to check for clusters
tolerances = np.arange(detectRyrTolInc, detectRyrTolMax, detectRyrTolInc)
numTol = len(tolerances)
# Choose slices 
multiSliceData = []
multiBgrData = []
multiMask = []

#multiTolerances = []
#sliceList = list(range((int(yLen/2) - numSlicesEachSide), (int(yLen/2) + numSlicesEachSide)))
#sliceList = list(np.linspace(1, yLen-1, yLen/2, dtype="int"))

sliceList = list(np.arange(5, yLen-4, 2, dtype="int"))
numSlices = len(sliceList)

multiRyrClusterCenters = np.full((numSlices, numTol, maxClustersPerSlice, 2), np.nan)
for s in range(numSlices):
    ySlice = sliceList[s]
    yLocation = y[ySlice]
    numDetect = 0
    ryrSliceCenters = []
    for tol in range(numTol):
        detectRyrTol = tolerances[tol]
        centersTemp = ryrCenters[np.where(np.isclose(ryrCenters[:, 1], yLocation, atol=detectRyrTol))]
        numDetect = len(centersTemp)
        scaled = (np.delete(centersTemp, 1, axis = 1) / (regSpace*outputSpacingStep)
                  + padding*outputSpacingStep
                  + 1.)  # pixel space conversions 
        multiRyrClusterCenters[s, tol,:numDetect] = scaled
    # mask
    print('surface mask used: ' + surfaceMaskFile)
    mesh = trimesh.load(surfaceMaskFile)
    # mask out the points outside of the mesh
    print('checking if pixels in mesh...')
    ySliceGrid = grid[np.where(np.isclose(grid[:, 1], yLocation, atol=detectRyrTolInc))]
    mask = mesh.contains(ySliceGrid)
    print('Calculating distance from triangulated surfaces')
    (closest_points, distances, triangle_id) = mesh.nearest.on_surface(ySliceGrid)
    maskOut = np.full((xLen, zLen), True, dtype=bool)
    c = 0
    for i in range(xLen):
        for k in range(zLen):
            if not mask[c]:
                maskOut[i, k] = False
            if distances[c] < boundaryTol:
                maskOut[i, k] = False
            c += 1
    mask_out_slice = maskOut
    # zeroed background image
    # x, y , and t resolution
    convolvedReduced = convolved[:, 0:gridDimensions[0]:outputSpacingStep,
                                 0:gridDimensions[1]:outputSpacingStep,
                                 0:gridDimensions[2]:outputSpacingStep]
    sliceData = np.moveaxis(np.squeeze(convolvedReduced[:, :, ySlice, :]), 0, 2)
    # Add noise
    noisySliceData = np.zeros_like(sliceData)
    bgr = np.zeros_like(sliceData)
    stdDev = np.mean(sliceData[:, :, 0]) / SNR
    for timestep in range(numberOfTimesteps):
        noise1 = np.random.normal(0, stdDev, [xLen, zLen])
        noise2 = np.random.normal(0, stdDev, [xLen, zLen])
        noisySliceData[:, :, timestep] = sliceData[:, :, timestep] + noise1
        bgr[:, :, timestep] = sliceData[:, :, 0] + noise2
    multiSliceData.append(noisySliceData)
    multiBgrData.append(bgr)
    multiMask.append(mask_out_slice)
    #multiRyrClusterCenters.append(ryrSliceCentersScaled)
    #multiTolerances.append(tolerances)

xyt = [x[1]-x[0], z[1]-z[0], timeIncrement*outputFrequency]
outString = caclean_path + "input/scipyConvolve_batchAll_wideSlice_psf107HalfZ_interp"+ str(int(regSpace*1000)) + "_SNR" + str(int(SNR)) + '_' + spacingType + '_' + mitoModel + '_' + str(xLen) + 'x' + str(zLen) + 'x' + str(numberOfTimesteps) + '_multDetect'

outputFile = outString + '.mat'
print('Writing MatLab file: ' + outputFile)
scipy.io.savemat(outputFile, mdict={'MultiMask': multiMask,
                                    'MultiRyrClusterCenters': multiRyrClusterCenters,
                                    'RyrTolerances': tolerances,
                                    'MultiBgr': multiBgrData,
                                    'MultiIdenoised': multiSliceData,
                                    'xyt_dim': xyt})


# # timestep = 4
# # temp_nn_interp= naturalneighbor.griddata(nodeGeom, specData[timestep], grid_ranges)
# fig = plt.figure()
# ax = fig.add_subplot(111)
# #im = ax.imshow(temp_nn_interp[:,50,:])
# #im = ax.imshow(nn_interp[4,:,50,:])
# im = ax.imshow(multiSliceData[5][:,:,4])
# plt.colorbar(im)
# plt.show()
# plt.close(fig)
